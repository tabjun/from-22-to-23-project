{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # 데이터 파일 불러오기 위한 패키지\n",
    "import os # 폴더 경로 설정을 위한 패키지\n",
    "import numpy as np # 데이터 배열 변환 및 계산을 위한 패키지\n",
    "from sklearn.model_selection import train_test_split # 데이터 Train, Validation으로 나눠주기 위한 패키지\n",
    "import statsmodels.api as sm # 로지스틱 회귀모형을 불러오기 위한 패키지\n",
    "from firthlogist import FirthLogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train import\n",
    "sas_train = pd.read_sas('C:/Users/Owner/Desktop/윤태준/소/3차 요청자료/230304_Analysis_도축개월28_35/testset.sas7bdat')\n",
    "# test import\n",
    "sas_val = pd.read_sas('C:/Users/Owner/Desktop/윤태준/소/3차 요청자료/230304_Analysis_도축개월28_35/validset.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_train.GENDER = pd.Series(sas_train['GENDER']).astype('object')\n",
    "sas_val.GENDER = pd.Series(sas_val['GENDER']).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>KPN</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BIR</th>\n",
       "      <th>FARM_ID</th>\n",
       "      <th>FARM_CLASS</th>\n",
       "      <th>SL_M</th>\n",
       "      <th>SL_D</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>S_W</th>\n",
       "      <th>...</th>\n",
       "      <th>D_ID</th>\n",
       "      <th>D_S_M_W</th>\n",
       "      <th>D_S_M_I</th>\n",
       "      <th>D_S_F_M</th>\n",
       "      <th>D_S_T_M</th>\n",
       "      <th>D_S_C</th>\n",
       "      <th>FARM_LEVEL</th>\n",
       "      <th>TARGET1</th>\n",
       "      <th>TARGET2</th>\n",
       "      <th>Replicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'000189678601'</td>\n",
       "      <td>b'KPN496'</td>\n",
       "      <td>b'\\xb0\\xc5\\xbc\\xbc'</td>\n",
       "      <td>b'2006-05-25'</td>\n",
       "      <td>78238.0</td>\n",
       "      <td>b'1+B'</td>\n",
       "      <td>32.0</td>\n",
       "      <td>b'2009-01-20'</td>\n",
       "      <td>b'1++B'</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'000189803362'</td>\n",
       "      <td>b'KPN485'</td>\n",
       "      <td>b'\\xb0\\xc5\\xbc\\xbc'</td>\n",
       "      <td>b'2006-03-03'</td>\n",
       "      <td>21396.0</td>\n",
       "      <td>b'1+C'</td>\n",
       "      <td>35.0</td>\n",
       "      <td>b'2009-01-07'</td>\n",
       "      <td>b'1B'</td>\n",
       "      <td>546.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'000194536248'</td>\n",
       "      <td>b'KPN496'</td>\n",
       "      <td>b'\\xbe\\xcf'</td>\n",
       "      <td>b'2006-06-01'</td>\n",
       "      <td>99065.0</td>\n",
       "      <td>b'2B'</td>\n",
       "      <td>32.0</td>\n",
       "      <td>b'2009-01-10'</td>\n",
       "      <td>b'2B'</td>\n",
       "      <td>274.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'000195425435'</td>\n",
       "      <td>b'KPN363'</td>\n",
       "      <td>b'\\xb0\\xc5\\xbc\\xbc'</td>\n",
       "      <td>b'2006-04-19'</td>\n",
       "      <td>73033.0</td>\n",
       "      <td>b'1+B'</td>\n",
       "      <td>32.0</td>\n",
       "      <td>b'2008-12-03'</td>\n",
       "      <td>b'1++B'</td>\n",
       "      <td>457.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'000196536482'</td>\n",
       "      <td>b'KPN471'</td>\n",
       "      <td>b'\\xb0\\xc5\\xbc\\xbc'</td>\n",
       "      <td>b'2006-02-19'</td>\n",
       "      <td>71971.0</td>\n",
       "      <td>b'1A'</td>\n",
       "      <td>33.0</td>\n",
       "      <td>b'2008-10-24'</td>\n",
       "      <td>b'1+C'</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        KPN               GENDER            BIR  FARM_ID  \\\n",
       "0  b'000189678601'  b'KPN496'  b'\\xb0\\xc5\\xbc\\xbc'  b'2006-05-25'  78238.0   \n",
       "1  b'000189803362'  b'KPN485'  b'\\xb0\\xc5\\xbc\\xbc'  b'2006-03-03'  21396.0   \n",
       "2  b'000194536248'  b'KPN496'          b'\\xbe\\xcf'  b'2006-06-01'  99065.0   \n",
       "3  b'000195425435'  b'KPN363'  b'\\xb0\\xc5\\xbc\\xbc'  b'2006-04-19'  73033.0   \n",
       "4  b'000196536482'  b'KPN471'  b'\\xb0\\xc5\\xbc\\xbc'  b'2006-02-19'  71971.0   \n",
       "\n",
       "  FARM_CLASS  SL_M           SL_D    CLASS    S_W  ...  D_ID  D_S_M_W  \\\n",
       "0     b'1+B'  32.0  b'2009-01-20'  b'1++B'  406.0  ...   NaN      0.0   \n",
       "1     b'1+C'  35.0  b'2009-01-07'    b'1B'  546.0  ...   NaN      0.0   \n",
       "2      b'2B'  32.0  b'2009-01-10'    b'2B'  274.0  ...   NaN      0.0   \n",
       "3     b'1+B'  32.0  b'2008-12-03'  b'1++B'  457.0  ...   NaN      0.0   \n",
       "4      b'1A'  33.0  b'2008-10-24'   b'1+C'  490.0  ...   NaN      0.0   \n",
       "\n",
       "   D_S_M_I  D_S_F_M  D_S_T_M  D_S_C  FARM_LEVEL TARGET1  TARGET2  Replicate  \n",
       "0      0.0      0.0      0.0    0.0         2.0     1.0      0.0        1.0  \n",
       "1      0.0      0.0      0.0    0.0         2.0     0.0      0.0        1.0  \n",
       "2      0.0      0.0      0.0    0.0         3.0     0.0      0.0        1.0  \n",
       "3      0.0      0.0      0.0    0.0         2.0     1.0      1.0        1.0  \n",
       "4      0.0      0.0      0.0    0.0         3.0     1.0      0.0        1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modeling: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.594637\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                TARGET1   No. Observations:                52505\n",
      "Model:                          Logit   Df Residuals:                    52490\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Mon, 06 Mar 2023   Pseudo R-squ.:                 0.07380\n",
      "Time:                        11:56:41   Log-Likelihood:                -31221.\n",
      "converged:                       True   LL-Null:                       -33709.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                             -4.4252      0.217    -20.430      0.000      -4.850      -4.001\n",
      "C(GENDER)[T.b'\\xbe\\xcf']              -0.0146      0.033     -0.436      0.663      -0.080       0.051\n",
      "C(FARM_LEVEL, Treatment(3))[T.1.0]     2.1065      0.093     22.696      0.000       1.925       2.288\n",
      "C(FARM_LEVEL, Treatment(3))[T.2.0]     0.6739      0.021     31.452      0.000       0.632       0.716\n",
      "SL_M                                   0.0091      0.006      1.651      0.099      -0.002       0.020\n",
      "S_W                                    0.0062      0.000     31.822      0.000       0.006       0.007\n",
      "S_M_W                                 -0.0018      0.000     -9.548      0.000      -0.002      -0.001\n",
      "S_F_M                                 -0.0068      0.002     -2.891      0.004      -0.011      -0.002\n",
      "S_T_M                                  0.1755      0.006     27.435      0.000       0.163       0.188\n",
      "S_C                                   -0.0057      0.008     -0.755      0.450      -0.021       0.009\n",
      "A_S_M_W                               -0.0010      0.000     -5.019      0.000      -0.001      -0.001\n",
      "A_S_T_M                                0.0904      0.007     13.826      0.000       0.078       0.103\n",
      "B_S_M_W                               -0.0010      0.000     -4.003      0.000      -0.001      -0.000\n",
      "B_S_M_I                                0.0033      0.001      2.538      0.011       0.001       0.006\n",
      "B_S_T_M                                0.0336      0.007      5.133      0.000       0.021       0.046\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Odds_ratio(Confidence Interval)\n",
      "                                          OR  Lower CI  Upper CI\n",
      "Intercept                           0.011972  0.007830  0.018303\n",
      "C(GENDER)[T.b'\\xbe\\xcf']            0.985513  0.922917  1.052354\n",
      "C(FARM_LEVEL, Treatment(3))[T.1.0]  8.219444  6.852356  9.859276\n",
      "C(FARM_LEVEL, Treatment(3))[T.2.0]  1.961911  1.881224  2.046058\n",
      "SL_M                                1.009148  0.998300  1.020113\n",
      "S_W                                 1.006250  1.005864  1.006636\n",
      "S_M_W                               0.998179  0.997806  0.998552\n",
      "S_F_M                               0.993175  0.988573  0.997798\n",
      "S_T_M                               1.191827  1.176979  1.206863\n",
      "S_C                                 0.994282  0.979591  1.009193\n",
      "A_S_M_W                             0.999028  0.998648  0.999407\n",
      "A_S_T_M                             1.094628  1.080687  1.108749\n",
      "B_S_M_W                             0.999032  0.998559  0.999506\n",
      "B_S_M_I                             1.003348  1.000762  1.005941\n",
      "B_S_T_M                             1.034140  1.020969  1.047481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\anaconda3\\envs\\'cow'\\lib\\site-packages\\statsmodels\\base\\model.py:127: ValueWarning: unknown kwargs ['C', 'penalty', 'solver', 'tol']\n",
      "  warnings.warn(msg, ValueWarning)\n",
      "c:\\Users\\Owner\\anaconda3\\envs\\'cow'\\lib\\site-packages\\statsmodels\\base\\model.py:127: ValueWarning: unknown kwargs ['C', 'penalty', 'solver', 'tol']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "# scaled Train set, Logistic Regression.fit(), C()로 category변수 지정, Treatment로 ref설정\n",
    "model = sm.Logit.from_formula('''TARGET1 ~ C(GENDER) + C(FARM_LEVEL, Treatment(3)) + SL_M + S_W + S_M_W + S_F_M \n",
    "    + S_T_M + S_C + A_S_M_W + A_S_T_M + B_S_M_W \n",
    "    + B_S_M_I + B_S_T_M''', sas_train, C=1e8, penalty=None, solver='newton-cg', tol=0.00000001).fit()\n",
    "print(model.summary())\n",
    "print('\\n')\n",
    "# 오즈비 계산(Confidence interval 포함)\n",
    "odds_ratios = pd.DataFrame(\n",
    "    {\n",
    "        \"OR\": model.params,\n",
    "        \"Lower CI\": model.conf_int()[0],\n",
    "        \"Upper CI\": model.conf_int()[1],\n",
    "    }\n",
    ")\n",
    "odds_ratios = np.exp(odds_ratios)\n",
    "print('Odds_ratio(Confidence Interval)')\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Logit in module statsmodels.discrete.discrete_model:\n",
      "\n",
      "class Logit(BinaryModel)\n",
      " |  Logit(endog, exog, check_rank=True, **kwargs)\n",
      " |  \n",
      " |  Logit Model\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  check_rank : bool\n",
      " |      Check exog rank to determine model degrees of freedom. Default is\n",
      " |      True. Setting to False reduces model initialization time when\n",
      " |      exog.shape[1] is large.\n",
      " |  \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  endog : ndarray\n",
      " |      A reference to the endogenous response variable\n",
      " |  exog : ndarray\n",
      " |      A reference to the exogenous design.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Logit\n",
      " |      BinaryModel\n",
      " |      DiscreteModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  cdf(self, X)\n",
      " |      The logistic cumulative distribution function\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          `X` is the linear predictor of the logit model.  See notes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      1/(1 + exp(-X))\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the logit model,\n",
      " |      \n",
      " |      .. math:: \\Lambda\\left(x^{\\prime}\\beta\\right)=\n",
      " |                \\text{Prob}\\left(Y=1|x\\right)=\n",
      " |                \\frac{e^{x^{\\prime}\\beta}}{1+e^{x^{\\prime}\\beta}}\n",
      " |  \n",
      " |  fit(self, start_params=None, method='newton', maxiter=35, full_output=1, disp=1, callback=None, **kwargs)\n",
      " |      Fit the model using maximum likelihood.\n",
      " |      \n",
      " |      The rest of the docstring is from\n",
      " |      statsmodels.base.model.LikelihoodModel.fit\n",
      " |      \n",
      " |      Fit method for likelihood based models\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_params : array_like, optional\n",
      " |          Initial guess of the solution for the loglikelihood maximization.\n",
      " |          The default is an array of zeros.\n",
      " |      method : str, optional\n",
      " |          The `method` determines which solver from `scipy.optimize`\n",
      " |          is used, and it can be chosen from among the following strings:\n",
      " |      \n",
      " |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      " |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      " |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      " |          - 'powell' for modified Powell's method\n",
      " |          - 'cg' for conjugate gradient\n",
      " |          - 'ncg' for Newton-conjugate gradient\n",
      " |          - 'basinhopping' for global basin-hopping solver\n",
      " |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      " |      \n",
      " |          The explicit arguments in `fit` are passed to the solver,\n",
      " |          with the exception of the basin-hopping solver. Each\n",
      " |          solver has several optional arguments that are not the same across\n",
      " |          solvers. See the notes section below (or scipy.optimize) for the\n",
      " |          available arguments and for the list of explicit arguments that the\n",
      " |          basin-hopping solver supports.\n",
      " |      maxiter : int, optional\n",
      " |          The maximum number of iterations to perform.\n",
      " |      full_output : bool, optional\n",
      " |          Set to True to have all available output in the Results object's\n",
      " |          mle_retvals attribute. The output is dependent on the solver.\n",
      " |          See LikelihoodModelResults notes section for more information.\n",
      " |      disp : bool, optional\n",
      " |          Set to True to print convergence messages.\n",
      " |      fargs : tuple, optional\n",
      " |          Extra arguments passed to the likelihood function, i.e.,\n",
      " |          loglike(x,*args)\n",
      " |      callback : callable callback(xk), optional\n",
      " |          Called after each iteration, as callback(xk), where xk is the\n",
      " |          current parameter vector.\n",
      " |      retall : bool, optional\n",
      " |          Set to True to return list of solutions at each iteration.\n",
      " |          Available in Results object's mle_retvals attribute.\n",
      " |      skip_hessian : bool, optional\n",
      " |          If False (default), then the negative inverse hessian is calculated\n",
      " |          after the optimization. If True, then the hessian will not be\n",
      " |          calculated. However, it will be available in methods that use the\n",
      " |          hessian in the optimization (currently only with `\"newton\"`).\n",
      " |      kwargs : keywords\n",
      " |          All kwargs are passed to the chosen solver with one exception. The\n",
      " |          following keyword controls what happens after the fit::\n",
      " |      \n",
      " |              warn_convergence : bool, optional\n",
      " |                  If True, checks the model for the converged flag. If the\n",
      " |                  converged flag is False, a ConvergenceWarning is issued.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      " |      explicit arguments.\n",
      " |      \n",
      " |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      " |      \n",
      " |          'newton'\n",
      " |              tol : float\n",
      " |                  Relative error in params acceptable for convergence.\n",
      " |          'nm' -- Nelder Mead\n",
      " |              xtol : float\n",
      " |                  Relative error in params acceptable for convergence\n",
      " |              ftol : float\n",
      " |                  Relative error in loglike(params) acceptable for\n",
      " |                  convergence\n",
      " |              maxfun : int\n",
      " |                  Maximum number of function evaluations to make.\n",
      " |          'bfgs'\n",
      " |              gtol : float\n",
      " |                  Stop when norm of gradient is less than gtol.\n",
      " |              norm : float\n",
      " |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      " |              epsilon\n",
      " |                  If fprime is approximated, use this value for the step\n",
      " |                  size. Only relevant if LikelihoodModel.score is None.\n",
      " |          'lbfgs'\n",
      " |              m : int\n",
      " |                  This many terms are used for the Hessian approximation.\n",
      " |              factr : float\n",
      " |                  A stop condition that is a variant of relative error.\n",
      " |              pgtol : float\n",
      " |                  A stop condition that uses the projected gradient.\n",
      " |              epsilon\n",
      " |                  If fprime is approximated, use this value for the step\n",
      " |                  size. Only relevant if LikelihoodModel.score is None.\n",
      " |              maxfun : int\n",
      " |                  Maximum number of function evaluations to make.\n",
      " |              bounds : sequence\n",
      " |                  (min, max) pairs for each element in x,\n",
      " |                  defining the bounds on that parameter.\n",
      " |                  Use None for one of min or max when there is no bound\n",
      " |                  in that direction.\n",
      " |          'cg'\n",
      " |              gtol : float\n",
      " |                  Stop when norm of gradient is less than gtol.\n",
      " |              norm : float\n",
      " |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      " |              epsilon : float\n",
      " |                  If fprime is approximated, use this value for the step\n",
      " |                  size. Can be scalar or vector.  Only relevant if\n",
      " |                  Likelihoodmodel.score is None.\n",
      " |          'ncg'\n",
      " |              fhess_p : callable f'(x,*args)\n",
      " |                  Function which computes the Hessian of f times an arbitrary\n",
      " |                  vector, p.  Should only be supplied if\n",
      " |                  LikelihoodModel.hessian is None.\n",
      " |              avextol : float\n",
      " |                  Stop when the average relative error in the minimizer\n",
      " |                  falls below this amount.\n",
      " |              epsilon : float or ndarray\n",
      " |                  If fhess is approximated, use this value for the step size.\n",
      " |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      " |          'powell'\n",
      " |              xtol : float\n",
      " |                  Line-search error tolerance\n",
      " |              ftol : float\n",
      " |                  Relative error in loglike(params) for acceptable for\n",
      " |                  convergence.\n",
      " |              maxfun : int\n",
      " |                  Maximum number of function evaluations to make.\n",
      " |              start_direc : ndarray\n",
      " |                  Initial direction set.\n",
      " |          'basinhopping'\n",
      " |              niter : int\n",
      " |                  The number of basin hopping iterations.\n",
      " |              niter_success : int\n",
      " |                  Stop the run if the global minimum candidate remains the\n",
      " |                  same for this number of iterations.\n",
      " |              T : float\n",
      " |                  The \"temperature\" parameter for the accept or reject\n",
      " |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      " |                  in function value will be accepted. For best results\n",
      " |                  `T` should be comparable to the separation (in function\n",
      " |                  value) between local minima.\n",
      " |              stepsize : float\n",
      " |                  Initial step size for use in the random displacement.\n",
      " |              interval : int\n",
      " |                  The interval for how often to update the `stepsize`.\n",
      " |              minimizer : dict\n",
      " |                  Extra keyword arguments to be passed to the minimizer\n",
      " |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      " |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      " |                  tolerance for termination. Other arguments are mapped from\n",
      " |                  explicit argument of `fit`:\n",
      " |                    - `args` <- `fargs`\n",
      " |                    - `jac` <- `score`\n",
      " |                    - `hess` <- `hess`\n",
      " |          'minimize'\n",
      " |              min_method : str, optional\n",
      " |                  Name of minimization method to use.\n",
      " |                  Any method specific arguments can be passed directly.\n",
      " |                  For a list of methods and their arguments, see\n",
      " |                  documentation of `scipy.optimize.minimize`.\n",
      " |                  If no method is specified, then BFGS is used.\n",
      " |  \n",
      " |  hessian(self, params)\n",
      " |      Logit model Hessian matrix of the log-likelihood\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameters of the model\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      hess : ndarray, (k_vars, k_vars)\n",
      " |          The Hessian, second derivative of loglikelihood function,\n",
      " |          evaluated at `params`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math:: \\frac{\\partial^{2}\\ln L}{\\partial\\beta\\partial\\beta^{\\prime}}=-\\sum_{i}\\Lambda_{i}\\left(1-\\Lambda_{i}\\right)x_{i}x_{i}^{\\prime}\n",
      " |  \n",
      " |  loglike(self, params)\n",
      " |      Log-likelihood of logit model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameters of the logit model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      loglike : float\n",
      " |          The log-likelihood function of the model evaluated at `params`.\n",
      " |          See notes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math::\n",
      " |      \n",
      " |         \\ln L=\\sum_{i}\\ln\\Lambda\n",
      " |         \\left(q_{i}x_{i}^{\\prime}\\beta\\right)\n",
      " |      \n",
      " |      Where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      " |      logistic distribution is symmetric.\n",
      " |  \n",
      " |  loglikeobs(self, params)\n",
      " |      Log-likelihood of logit model for each observation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameters of the logit model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      loglike : ndarray\n",
      " |          The log likelihood for each observation of the model evaluated\n",
      " |          at `params`. See Notes\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math::\n",
      " |      \n",
      " |         \\ln L=\\sum_{i}\\ln\\Lambda\n",
      " |         \\left(q_{i}x_{i}^{\\prime}\\beta\\right)\n",
      " |      \n",
      " |      for observations :math:`i=1,...,n`\n",
      " |      \n",
      " |      where :math:`q=2y-1`. This simplification comes from the fact that the\n",
      " |      logistic distribution is symmetric.\n",
      " |  \n",
      " |  pdf(self, X)\n",
      " |      The logistic probability density function\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          `X` is the linear predictor of the logit model.  See notes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pdf : ndarray\n",
      " |          The value of the Logit probability mass function, PMF, for each\n",
      " |          point of X. ``np.exp(-x)/(1+np.exp(-X))**2``\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the logit model,\n",
      " |      \n",
      " |      .. math:: \\lambda\\left(x^{\\prime}\\beta\\right)=\\frac{e^{-x^{\\prime}\\beta}}{\\left(1+e^{-x^{\\prime}\\beta}\\right)^{2}}\n",
      " |  \n",
      " |  score(self, params)\n",
      " |      Logit model score (gradient) vector of the log-likelihood\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameters of the model\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray, 1-D\n",
      " |          The score vector of the model, i.e. the first derivative of the\n",
      " |          loglikelihood function, evaluated at `params`\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math:: \\frac{\\partial\\ln L}{\\partial\\beta}=\\sum_{i=1}^{n}\\left(y_{i}-\\Lambda_{i}\\right)x_{i}\n",
      " |  \n",
      " |  score_obs(self, params)\n",
      " |      Logit model Jacobian of the log-likelihood for each observation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The parameters of the model\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      jac : array_like\n",
      " |          The derivative of the loglikelihood for each observation evaluated\n",
      " |          at `params`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math:: \\frac{\\partial\\ln L_{i}}{\\partial\\beta}=\\left(y_{i}-\\Lambda_{i}\\right)x_{i}\n",
      " |      \n",
      " |      for observations :math:`i=1,...,n`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BinaryModel:\n",
      " |  \n",
      " |  __init__(self, endog, exog, check_rank=True, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_regularized(self, start_params=None, method='l1', maxiter='defined_by_method', full_output=1, disp=1, callback=None, alpha=0, trim_mode='auto', auto_trim_tol=0.01, size_trim_tol=0.0001, qc_tol=0.03, **kwargs)\n",
      " |      Fit the model using a regularized maximum likelihood.\n",
      " |      \n",
      " |      The regularization method AND the solver used is determined by the\n",
      " |      argument method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_params : array_like, optional\n",
      " |          Initial guess of the solution for the loglikelihood maximization.\n",
      " |          The default is an array of zeros.\n",
      " |      method : 'l1' or 'l1_cvxopt_cp'\n",
      " |          See notes for details.\n",
      " |      maxiter : {int, 'defined_by_method'}\n",
      " |          Maximum number of iterations to perform.\n",
      " |          If 'defined_by_method', then use method defaults (see notes).\n",
      " |      full_output : bool\n",
      " |          Set to True to have all available output in the Results object's\n",
      " |          mle_retvals attribute. The output is dependent on the solver.\n",
      " |          See LikelihoodModelResults notes section for more information.\n",
      " |      disp : bool\n",
      " |          Set to True to print convergence messages.\n",
      " |      fargs : tuple\n",
      " |          Extra arguments passed to the likelihood function, i.e.,\n",
      " |          loglike(x,*args).\n",
      " |      callback : callable callback(xk)\n",
      " |          Called after each iteration, as callback(xk), where xk is the\n",
      " |          current parameter vector.\n",
      " |      retall : bool\n",
      " |          Set to True to return list of solutions at each iteration.\n",
      " |          Available in Results object's mle_retvals attribute.\n",
      " |      alpha : non-negative scalar or numpy array (same size as parameters)\n",
      " |          The weight multiplying the l1 penalty term.\n",
      " |      trim_mode : 'auto, 'size', or 'off'\n",
      " |          If not 'off', trim (set to zero) parameters that would have been\n",
      " |          zero if the solver reached the theoretical minimum.\n",
      " |          If 'auto', trim params using the Theory above.\n",
      " |          If 'size', trim params if they have very small absolute value.\n",
      " |      size_trim_tol : float or 'auto' (default = 'auto')\n",
      " |          Tolerance used when trim_mode == 'size'.\n",
      " |      auto_trim_tol : float\n",
      " |          Tolerance used when trim_mode == 'auto'.\n",
      " |      qc_tol : float\n",
      " |          Print warning and do not allow auto trim when (ii) (above) is\n",
      " |          violated by this much.\n",
      " |      qc_verbose : bool\n",
      " |          If true, print out a full QC report upon failure.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments used when fitting the model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Results\n",
      " |          A results instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Using 'l1_cvxopt_cp' requires the cvxopt module.\n",
      " |      \n",
      " |      Extra parameters are not penalized if alpha is given as a scalar.\n",
      " |      An example is the shape parameter in NegativeBinomial `nb1` and `nb2`.\n",
      " |      \n",
      " |      Optional arguments for the solvers (available in Results.mle_settings)::\n",
      " |      \n",
      " |          'l1'\n",
      " |              acc : float (default 1e-6)\n",
      " |                  Requested accuracy as used by slsqp\n",
      " |          'l1_cvxopt_cp'\n",
      " |              abstol : float\n",
      " |                  absolute accuracy (default: 1e-7).\n",
      " |              reltol : float\n",
      " |                  relative accuracy (default: 1e-6).\n",
      " |              feastol : float\n",
      " |                  tolerance for feasibility conditions (default: 1e-7).\n",
      " |              refinement : int\n",
      " |                  number of iterative refinement steps when solving KKT\n",
      " |                  equations (default: 1).\n",
      " |      \n",
      " |      Optimization methodology\n",
      " |      \n",
      " |      With :math:`L` the negative log likelihood, we solve the convex but\n",
      " |      non-smooth problem\n",
      " |      \n",
      " |      .. math:: \\min_\\beta L(\\beta) + \\sum_k\\alpha_k |\\beta_k|\n",
      " |      \n",
      " |      via the transformation to the smooth, convex, constrained problem\n",
      " |      in twice as many variables (adding the \"added variables\" :math:`u_k`)\n",
      " |      \n",
      " |      .. math:: \\min_{\\beta,u} L(\\beta) + \\sum_k\\alpha_k u_k,\n",
      " |      \n",
      " |      subject to\n",
      " |      \n",
      " |      .. math:: -u_k \\leq \\beta_k \\leq u_k.\n",
      " |      \n",
      " |      With :math:`\\partial_k L` the derivative of :math:`L` in the\n",
      " |      :math:`k^{th}` parameter direction, theory dictates that, at the\n",
      " |      minimum, exactly one of two conditions holds:\n",
      " |      \n",
      " |      (i) :math:`|\\partial_k L| = \\alpha_k`  and  :math:`\\beta_k \\neq 0`\n",
      " |      (ii) :math:`|\\partial_k L| \\leq \\alpha_k`  and  :math:`\\beta_k = 0`\n",
      " |  \n",
      " |  predict(self, params, exog=None, linear=False)\n",
      " |      Predict response variable of a model given exogenous variables.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Fitted parameters of the model.\n",
      " |      exog : array_like\n",
      " |          1d or 2d array of exogenous values.  If not supplied, the\n",
      " |          whole exog attribute of the model is used.\n",
      " |      linear : bool, optional\n",
      " |          If True, returns the linear predictor dot(exog,params).  Else,\n",
      " |          returns the value of the cdf at the linear predictor.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array\n",
      " |          Fitted values at exog.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DiscreteModel:\n",
      " |  \n",
      " |  cov_params_func_l1(self, likelihood_model, xopt, retvals)\n",
      " |      Computes cov_params on a reduced parameter space\n",
      " |      corresponding to the nonzero parameters resulting from the\n",
      " |      l1 regularized fit.\n",
      " |      \n",
      " |      Returns a full cov_params matrix, with entries corresponding\n",
      " |      to zero'd values set to np.nan.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize is called by\n",
      " |      statsmodels.model.LikelihoodModel.__init__\n",
      " |      and should contain any preprocessing that needs to be done for a model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |      \n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.Logit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'cow'",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643e8b1da7b496eadedb6813c3048d428a1881cf2325a1f39b02fd04f838288a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
